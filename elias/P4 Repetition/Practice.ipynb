{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Practice",
   "id": "25ef229349c3b7b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Libraries",
   "id": "fdbd73feefe59b5e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-09T13:18:44.298106Z",
     "start_time": "2024-06-09T13:18:44.288913Z"
    }
   },
   "source": [
    "from termcolor import colored # type: ignore                                          # Colored text\n",
    "from random import Random  # type: ignore                                             # Random number generator\n",
    "import math  # type: ignore                                                           # Mathematical functions\n",
    "import pandas as pd  # type: ignore                                                   # Data manipulation\n",
    "import numpy as np  # type: ignore                                                    # Scientific computing\n",
    "import matplotlib.pyplot as plt  # type: ignore                                       # Data visualization\n",
    "from scipy.stats import binom as binomial  # type: ignore                             # Binomial distribution\n",
    "from scipy.stats import norm as normal  # type: ignore                                # Normal distribution\n",
    "from scipy.stats import poisson as poisson  # type: ignore                            # Poisson distribution\n",
    "from scipy.stats import t as student  # type: ignore                                  # Student distribution\n",
    "from scipy.stats import chi2  # type: ignore                                          # Chi-squared distribution\n",
    "from scipy.stats import ttest_1samp  # type: ignore                                   # One-sample t-test\n",
    "from scipy.stats import chisquare  # type: ignore                                     # Chi-squared test\n",
    "from scipy.special import comb  # type: ignore                                        # Combinations\n",
    "from mlxtend.frequent_patterns import apriori  # type: ignore                         # Apriori algorithm\n",
    "from mlxtend.frequent_patterns import fpgrowth  # type: ignore                        # FP-growth algorithm\n",
    "from mlxtend.frequent_patterns import association_rules  # type: ignore               # Association rules\n",
    "from mlxtend.preprocessing import TransactionEncoder  # type: ignore                  # Transaction encoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis  # type: ignore  # Discriminant Analysis\n",
    "from tensorflow import keras  # type: ignore                                          # Deep Learning library\n",
    "from tensorflow.keras import Model  # type: ignore                                    # Model class\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization  # type: ignore  # Layers\n",
    "from tensorflow.keras.utils import to_categorical  # type: ignore                     # One-hot encoding\n",
    "from tensorflow.keras.optimizers import Adam  # type: ignore                          # Optimizer\n",
    "from livelossplot import PlotLossesKeras  # type: ignore                              # Live plot\n",
    "from keras.src.optimizers import RMSprop  # type: ignore                              # Optimizer\n",
    "from sklearn.model_selection import train_test_split  # type: ignore                  # Train-test split\n",
    "from sklearn.metrics import roc_auc_score # type: ignore                              # ROC AUC score\n",
    "from simanneal import Annealer  # type: ignore                                        # Simulated Annealing\n",
    "from inspyred import ec  # type: ignore                                               # Evolutionary Computation\n",
    "import warnings  # type: ignore                                                       # Disable warnings\n",
    "from Resources.Functions import *  # type: ignore                                     # Custom functions\n",
    "warnings.filterwarnings(\"ignore\")                                                     # Disable warnings\n",
    "outputColor = \"blue\"                                                                  # Color for the output"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Information About the Dataset\n",
    "- Information about the dataset `../Data/Gesture-Original.csv` used in the following questions.\n",
    "- This dataset contains data from 64 muscle sensors `V1 - V64` that are placed on the body of test subjects. In addition, the file contains 2 columns.\n",
    "- `gesture` always contains the hand gesture performed by a test subject during the measurement of the 64 sensors. The possible values `Pare`, `rock`, `paper`, `scissors`\n",
    "and `okay`.\n",
    "- The `okay` column does not contain any new data, but simply indicates whether the subject performed the `okay` hand gesture during the measurement."
   ],
   "id": "91c17ba492416214"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T13:33:36.637701Z",
     "start_time": "2024-06-09T13:33:36.571200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load in data and filter data\n",
    "gestureOriginal = pd.read_csv(\"../Data/Gesture-Original.csv\", delimiter=';')"
   ],
   "id": "b0779b3ad3a94f1e",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 1:\n",
    "- Apply linear discriminant analysis to the `../Data/Gesture-Original.csv` dataset.\n",
    "- `gesture` is the dependent variable.\n",
    "- Use all other variables as independent variables except the column Okay.\n",
    "\n",
    "Answer the following questions:\n",
    "- One of the assumptions for being able to apply LDA is that there is no dependence exists between the independent variables. Show that here or not is met.2. \n",
    "- How many discriminant functions are created?\n",
    "- Why exactly are there so many?\n",
    "- Which independent variable plays the largest role in the first discriminant function? Please indicate how you got here."
   ],
   "id": "93b079662452c29f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T13:33:38.521893Z",
     "start_time": "2024-06-09T13:33:38.415404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create linear discriminant analysis model\n",
    "# independentVariables = gestureOriginal[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64']]\n",
    "\n",
    "independentVariables = gestureOriginal.drop(columns=['gesture', 'okay'])                                                        # Independent variables\n",
    "dependentVariable = gestureOriginal['gesture']                                                                                  # Dependent variable\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(independentVariables, dependentVariable)\n",
    "\n",
    "# independentVariables.describe()\n",
    "# independentVariables.corr(method='pearson')\n",
    "\n",
    "# Show some information about the discriminant analysis\n",
    "print(colored(f\"There are {(len(dependentVariable.unique()))-1} dimensions and there are {len(dependentVariable.unique())} different possibilities for the dependent variable and also, there are {len(independentVariables.columns)} independent variables. And there are {min(len(gestureOriginal['gesture'].unique()) - 1, independentVariables.shape[1])} discriminant functions.\", outputColor))\n",
    "print(colored(f\"\\nThe reason for the number of discriminant functions is that the number of discriminant functions is the minimum of the number of dependent variables and the number of independent variables.\", outputColor))"
   ],
   "id": "d13cf98f368f5d84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mThere are 3 dimensions and there are 4 different possibilities for the dependent variable and also, there are 64 independent variables. And there are 3 discriminant functions.\u001B[0m\n",
      "\u001B[34m\n",
      "The reason for the number of discriminant functions is that the number of discriminant functions is the minimum of the number of dependent variables and the number of independent variables.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T13:33:40.376826Z",
     "start_time": "2024-06-09T13:33:40.284952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Determine the most important variable\n",
    "result = most_important_variable(independentVariables, dependentVariable)\n",
    "\n",
    "# Print the most important variable\n",
    "print(colored(\"The independent variable that plays the most significant role in the first discriminant function is:\", outputColor))\n",
    "print(colored(f\"Variable: {result['Variable']}, Coefficient: {result['Coefficient']}\", outputColor))"
   ],
   "id": "f1b9e55d4f20d416",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mThe independent variable that plays the most significant role in the first discriminant function is:\u001B[0m\n",
      "\u001B[34mVariable: V39, Coefficient: 0.006181404091898121\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 2:\n",
    "- With 64 independent variables we are dealing with a rather large number.\n",
    "    - Use proper technique to limit the number of variables.\n",
    "    - I want to limit myself to 10 variables. What percentage of the information from the original. Can I keep the dataset with this?\n",
    "    - Explain how you arrived at this number?\n",
    "    - Create a data set with those 10 variables.\n",
    "        - Perform a discriminant analysis. Compare the explained variance with that of the previous exercise."
   ],
   "id": "1cb761421f5700a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T13:56:15.118679Z",
     "start_time": "2024-06-09T13:56:15.055034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Limit the number of variables\n",
    "pca_dim = min(independentVariables.shape[1], independentVariables.shape[0])                                             # Number of dimensions (dependent variables)\n",
    "pcamodel = PCA(n_components=pca_dim)                                                                                    # Create PCA model\n",
    "principalComponents = pcamodel.fit_transform(independentVariables)                                                      # Fit and transform the data\n",
    "col_names = ['PC{}'.format(i) for i in range(1, 11)]                                                                    # Get the column names\n",
    "new_independentVariables = pd.DataFrame(data=principalComponents[:,[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], columns= col_names) # Create a new dataframe with the principal components\n",
    "\n",
    "# Conclusion what did we do. We combined the 64 independent variables into 10 principal components, and we used these 10 principal components as independent variables.\n",
    "print(colored(f\"The new dataset contains {new_independentVariables.shape[1]} independent variables.\", outputColor))\n",
    "\n",
    "print(colored(f\"We expect to keep {round(pcamodel.explained_variance_ratio_[range(0,10)].sum() * 100, 2)}% of the information from the original dataset.\", outputColor))\n",
    "\n",
    "# Explain how we arrived at this number\n",
    "print(colored(f\"\\nWe arrived at this number by calculating the sum of the explained variance ratios of the first 10 principal components.\", outputColor))"
   ],
   "id": "c8be5cc3487395ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mThe new dataset contains 10 independent variables.\u001B[0m\n",
      "\u001B[34mWe expect to keep 51.83% of the information from the original dataset.\u001B[0m\n",
      "\u001B[34m\n",
      "We arrived at this number by calculating the sum of the explained variance ratios of the first 10 principal components.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T14:06:31.208024Z",
     "start_time": "2024-06-09T14:06:31.160650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a new discriminant analysis model\n",
    "lda_new = LinearDiscriminantAnalysis()\n",
    "lda_new.fit(new_independentVariables, dependentVariable)\n",
    "\n",
    "# Compare the lda models with lda_new model\n",
    "print(colored(f\"The first discriminant function of the new model explains {round(lda_new.explained_variance_ratio_[0] * 100, 2)}% of the variance.\", outputColor))\n",
    "print(colored(f\"The first discriminant function of the old model explains {round(lda.explained_variance_ratio_[0] * 100, 2)}% of the variance.\", outputColor))\n",
    "\n",
    "print(colored(f\"\\nThe second discriminant function of the new model explains {round(lda_new.explained_variance_ratio_[1] * 100, 2)}% of the variance.\", outputColor))\n",
    "print(colored(f\"The second discriminant function of the old model explains {round(lda.explained_variance_ratio_[1] * 100, 2)}% of the variance.\", outputColor))\n",
    "\n",
    "print(colored(f\"\\nThe third discriminant function of the new model explains {round(lda_new.explained_variance_ratio_[2] * 100, 2)}% of the variance.\", outputColor))\n",
    "print(colored(f\"The third discriminant function of the old model explains {round(lda.explained_variance_ratio_[2] * 100, 2)}% of the variance.\", outputColor))\n",
    "\n",
    "print(colored(f\"\\nWe can obviously see that the old model with more independent variables can quicker explain more variance than the new model with less independent variables.\", outputColor))"
   ],
   "id": "c6517b87614c8302",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mThe first discriminant function of the new model explains 72.63% of the variance.\u001B[0m\n",
      "\u001B[34mThe first discriminant function of the old model explains 91.15% of the variance.\u001B[0m\n",
      "\u001B[34m\n",
      "The second discriminant function of the new model explains 16.87% of the variance.\u001B[0m\n",
      "\u001B[34mThe second discriminant function of the old model explains 5.33% of the variance.\u001B[0m\n",
      "\u001B[34m\n",
      "The third discriminant function of the new model explains 10.5% of the variance.\u001B[0m\n",
      "\u001B[34mThe third discriminant function of the old model explains 3.52% of the variance.\u001B[0m\n",
      "\u001B[34m\n",
      "We can obviously see that the old model with more independent variables can quicker explain more variance than the new model with less independent variables.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 3:\n",
    "- We created our own model with more test data to predict whether someone will have it performs `okay` hand gesture. The data is available in `../Data/Gesture-Original.csv`. Note that the predicted values pare not just `0` or `1`, but can be close to `0` or close to `1` or somewhere in between. Take `0.5` as the threshold.\n",
    "\n",
    "Answer the following questions:\n",
    "- You want to know how well the model can predict whether the test subject has diabetes performing `okay` gesture. What metric do you use?\n",
    "- How much is this?\n",
    "- Calculate the F-measure in which the importance of recall and precision is equal weigh. How much is this?\n",
    "- Create an ROC curve.\n",
    "- What is the AUC?\n",
    "- What can you conclude based on the answer to question e?"
   ],
   "id": "6e945f7de7257a05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T13:18:44.596641Z",
     "start_time": "2024-06-09T13:18:44.582561Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ffa6c45ecd2573e6",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 4:\n",
    "Use dataframe `../Data/Gesture-Original.csv` to train an artificial neural network around the column predict `okay`.\n",
    "- Scale the data with min-max normalization\n",
    "- Create a neural network model for the entire data set with the following values for the parameters:\n",
    "    - 4 hidden layers: 32, 16, 8 and 4 neurons\n",
    "    - learning rate = 0.001\n",
    "    - epochs=100\n",
    "    - Make the right choices according to the objective of the ANN - for the other parameters involved correspond to the functions used."
   ],
   "id": "aeaf26ee4d9de5e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T13:18:44.611506Z",
     "start_time": "2024-06-09T13:18:44.598636Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a333f15e8a1d8e71",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 5:\n",
    "We want to solve the following optimization problem without doing the calculations ourselves:\n",
    "- You have `30` cards, each with its own value: 2, 4, 6, ..., 60.\n",
    "- You must divide the cards into two piles so that the sum of all values of pile `1`.\n",
    "- As close as possible to `2` times the sum of stack `2`.\n",
    "\n",
    "Answer the following questions:\n",
    "- Solve this problem with a genetic algorithm. Make sure you use the following parameters:\n",
    " - popSize=100\n",
    " - max_evaluations=5000\n",
    " -run=100\n",
    " - mutation_rate = 0.1\n",
    "- Which cards are in pile `1`? Also indicate how you arrived at this.\n",
    "- How much difference is there between the sum of stack `1` and `2` * the sum of stack `2`?\n",
    "- Are you sure there isn't a better solution? And why?\n"
   ],
   "id": "c3fb36e0490ff414"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T13:18:44.626855Z",
     "start_time": "2024-06-09T13:18:44.612508Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3c88c63ce8e27890",
   "outputs": [],
   "execution_count": 45
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
